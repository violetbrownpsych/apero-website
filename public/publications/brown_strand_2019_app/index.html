<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.120.4">
<title>&#34;Paying&#34; Attention to Audiovisual Speech: Do Incongruent Stimuli Incur Greater Costs? | Violet Brown</title>


<meta property="twitter:site" content="@violetsarebrown">
<meta property="twitter:creator" content="@violetsarebrown">







  
    
  
<meta name="description" content="Attention, Perception, &amp; Psychophysics">


<meta property="og:site_name" content="Violet Brown">
<meta property="og:title" content="&#34;Paying&#34; Attention to Audiovisual Speech: Do Incongruent Stimuli Incur Greater Costs? | Violet Brown">
<meta property="og:description" content="Attention, Perception, &amp; Psychophysics" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://www.violetabrown.com/publications/brown_strand_2019_app/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://www.violetabrown.com/publications/brown_strand_2019_app/featured_pdf.png" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://www.violetabrown.com/publications/brown_strand_2019_app/featured_pdf.png" >
    
    
  <meta itemprop="name" content="&#34;Paying&#34; Attention to Audiovisual Speech: Do Incongruent Stimuli Incur Greater Costs?">
<meta itemprop="description" content="The McGurk effect is a multisensory phenomenon in which discrepant auditory and visual speech signals typically result in an illusory percept. McGurk stimuli are often used in studies assessing the attentional requirements of audiovisual integration, but no study has directly compared the costs associated with integrating congruent versus incongruent audiovisual speech. Some evidence suggests that the McGurk effect may not be representative of naturalistic audiovisual speech processing – susceptibility to the McGurk effect is not associated with the ability to derive benefit from the addition of the visual signal, and distinct cortical regions are recruited when processing congruent versus incongruent speech."><meta itemprop="datePublished" content="2019-06-13T00:00:00+00:00" />
<meta itemprop="dateModified" content="2019-06-13T00:00:00+00:00" />
<meta itemprop="wordCount" content="235"><meta itemprop="image" content="https://www.violetabrown.com/publications/brown_strand_2019_app/featured_pdf.png">
<meta itemprop="keywords" content="mcgurk effect,audiovisual speech,dual-task,listening effort,measurement,speech perception," />
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/VB_logo.PNG" type="image/x-icon">
  <link rel="icon" href="/img/VB_logo.PNG" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.fc600ce742546fe629720c5a8ad0a1143c5cccce1be48e78180e574fed054b26.css" integrity="sha256-/GAM50JUb&#43;YpcgxaitChFDxczM4b5I54GA5XT&#43;0FSyY=" media="screen">
  
  
  <script src="/panelset.min.ed1ac24b6e16f4e2481e3d1d098ae66f5bc77438aef619e6e266d8ac5b00dc72.js" type="text/javascript"></script>
  
  
  <script src="/main.min.246e5a66bb6a18a599cc04627eb601304290680d3fc34f912389a3a5d8123494.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container single">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://www.violetabrown.com" title="Home">
      <img src="/img/VB_logo.PNG" class="dib db-l h2 w-auto" alt="Violet Brown">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/" title="Home">Home</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/publications/" title="Publications">Publications</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/resources_tutorials" title="Resources and Tutorials">Resources and Tutorials</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="http://violetabrown.com/pdfs/brown_cv.pdf" title="CV">CV</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">&#34;Paying&#34; Attention to Audiovisual Speech: Do Incongruent Stimuli Incur Greater Costs?</h1>
        <h4 class="f4 mt0 mb4 lh-title measure">Attention, Perception, &amp; Psychophysics</h4>
        
        

      
      <div class="ph0 pt5">
        
    
    
    
    
    
    
    
      
      
  <a class="btn-links mr2 ba dib" href="https://osf.io/8t7an" target="_blank" rel="noopener"><i class="ai ai-osf fa-lg fa-fw mr2"></i>OSF</a>

    
    
    
    
    
    
    
      
      
  <a class="btn-links mr2 ba dib" href="https://link.springer.com/article/10.3758/s13414-019-01772-x" target="_blank" rel="noopener"><i class="ai ai-doi fa-lg fa-fw mr2"></i>Publication</a>

    
    
    
    
    
    
    
      
      
  <a class="btn-links mr2 ba dib" href="/pdfs/Brown%20and%20Strand%202019%20-%20Paying%20attention%20to%20audiovisual%20speech%20-%20Do%20incongruent%20stimuli%20incur%20greater%20costs.pdf" ><i class="fa fa-file-pdf fa-lg fa-fw mr2"></i>PDF</a>


      </div>
      

      </header>
      <section class="post-body pt5 pb4">
        <p>The McGurk effect is a multisensory phenomenon in which discrepant auditory and visual speech signals typically result in an illusory percept. McGurk stimuli are often used in studies assessing the attentional requirements of audiovisual integration, but no study has directly compared the costs associated with integrating congruent versus incongruent audiovisual speech. Some evidence suggests that the McGurk effect may not be representative of naturalistic audiovisual speech processing – susceptibility to the McGurk effect is not associated with the ability to derive benefit from the addition of the visual signal, and distinct cortical regions are recruited when processing congruent versus incongruent speech. In two experiments, one using response times to identify congruent and incongruent syllables and one using a dual-task paradigm, we assessed whether congruent and incongruent audiovisual speech incur different attentional costs. We demonstrated that response times to both the speech task (Experiment 1) and a secondary vibrotactile task (Experiment 2) were indistinguishable for congruent compared to incongruent syllables, but McGurk fusions were responded to more quickly than McGurk non-fusions. These results suggest that despite documented differences in how congruent and incongruent stimuli are processed, they do not appear to differ in terms of processing time or effort, at least in the open-set task speech task used here. However, responses that result in McGurk fusions are processed more quickly than those that result in non-fusions, though attentional cost is comparable for the two response types.</p>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">June 13, 2019</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">2 minute read, 235 words</dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Tags:</dt>
    <dd class="fw5 ml0"> <a href="https://www.violetabrown.com/tags/mcgurk-effect">mcgurk effect</a>  <a href="https://www.violetabrown.com/tags/audiovisual-speech">audiovisual speech</a>  <a href="https://www.violetabrown.com/tags/dual-task">dual-task</a>  <a href="https://www.violetabrown.com/tags/listening-effort">listening effort</a>  <a href="https://www.violetabrown.com/tags/measurement">measurement</a>  <a href="https://www.violetabrown.com/tags/speech-perception">speech perception</a> </dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
    <dd class="fw5 ml0"><a href="/publications/brown_2025/">Measuring the Dual-Task Costs of Audiovisual Speech Processing Across Levels of Background Noise </a></dd>
    
    <dd class="fw5 ml0"><a href="/publications/sewell_etal_2023/">The Effects of Temporal Cues, Point-Light Displays, and Faces on Speech Identification and Listening Effort</a></dd>
    
    <dd class="fw5 ml0"><a href="/resources_tutorials/strand_brown_2023/">Spread the Word: Enhancing Replicability of Speech Research Through Stimulus Sharing</a></dd>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="https://www.violetabrown.com/publications/brown_strand_2019/">&larr; About Face: Seeing the Talker Improves Spoken  Word Recognition but Increases Listening Effort</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://www.violetabrown.com/publications/strand_brown_2019/">Publishing Open, Reproducible Research With Undergraduates &rarr;</a>
  
</div>

      </footer>
    </article>
    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2026 Violet A. Brown
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://bsky.app/profile/violetsarebrown.bsky.social" title="cloud-sun" target="_blank" rel="me noopener">
      <i class="fas fa-cloud-sun fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://twitter.com/violetsarebrown?lang=en" title="twitter" target="_blank" rel="me noopener">
      <i class="fab fa-twitter fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://osf.io/fzqc8/" title="osf" target="_blank" rel="me noopener">
      <i class="ai ai-osf fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/violetbrownpsych/apero-website" title="github" target="_blank" rel="me noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://orcid.org/my-orcid?orcid=0000-0001-5310-6499" title="orcid" target="_blank" rel="me noopener">
      <i class="ai ai-orcid fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.com/citations?user=SrLYUXMAAAAJ&amp;hl=en" title="google-scholar" target="_blank" rel="me noopener">
      <i class="ai ai-google-scholar fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="mailto:violet@violetabrown.com" title="envelope" >
      <i class="fas fa-envelope fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/license/" title="License">License</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
