<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dual-task on Violet Brown</title>
    <link>https://www.violetabrown.com/tags/dual-task/</link>
    <description>Recent content in dual-task on Violet Brown</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.violetabrown.com/tags/dual-task/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Measuring the Dual-Task Costs of Audiovisual Speech Processing Across Levels of Background Noise </title>
      <link>https://www.violetabrown.com/publications/brown_2025/</link>
      <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/brown_2025/</guid>
      <description>Successful communication requires that listeners not only identify speech, but do so while maintaining performance on other tasks, like remembering what a conversational partner said or paying attention while driving. This set of four experiments systematically evaluated how audiovisual speech—which reliably improves speech intelligibility—affects dual-task costs during speech perception (i.e., one facet of listening effort). Results indicated that audiovisual speech reduces dual-task costs in difficult listening conditions (those in which visual cues substantially benefit intelligibility), but may actually increase costs in easy conditions—a pattern of results that was internally replicated multiple times.</description>
    </item>
    <item>
      <title>Rapid Adaptation to Fully Intelligible Nonnative-Accented Speech Reduces Listening Effort</title>
      <link>https://www.violetabrown.com/publications/brown_etal_2020/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/brown_etal_2020/</guid>
      <description>In noisy settings or when listening to an unfamiliar talker or accent, it can be difficult to understand spoken language. This difficulty typically results in reductions in speech intelligibility, but may also increase the effort necessary to process the speech even when intelligibility is unaffected. In this study, we used a dual-task paradigm and pupillometry to assess the cognitive costs associated with processing fully intelligible accented speech, predicting that rapid perceptual adaptation to an accent would result in decreased listening effort over time.</description>
    </item>
    <item>
      <title>Talking Points: A Modulating Circle Increases Listening Effort Without Improving Speech Recognition in Young Adults</title>
      <link>https://www.violetabrown.com/publications/strand_brown_barbour_2020/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/strand_brown_barbour_2020/</guid>
      <description>Speech recognition is improved when the acoustic input is accompanied by visual cues provided by a talking face (Erber in Journal of Speech and Hearing Research, 12(2), 423–425, 1969; Sumby &amp;amp; Pollack in The Journal of the Acoustical Society of America, 26(2), 212–215, 1954). One way that the visual signal facilitates speech recognition is by providing the listener with information about fine phonetic detail that complements information from the auditory signal.</description>
    </item>
    <item>
      <title>About Face: Seeing the Talker Improves Spoken  Word Recognition but Increases Listening Effort</title>
      <link>https://www.violetabrown.com/publications/brown_strand_2019/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/brown_strand_2019/</guid>
      <description>It is widely accepted that seeing a talker improves a listener’s ability to understand what a talker is saying in background noise (e.g., Erber, 1969; Sumby &amp;amp; Pollack, 1954). The literature is mixed, however, regarding the influence of the visual modality on the listening effort required to recognize speech (e.g., Fraser, Gagné, Alepins, &amp;amp; Dubois, 2010; Sommers &amp;amp; Phelps, 2016). Here, we present data showing that even when the visual modality robustly benefits recognition, processing audiovisual speech can still result in greater cognitive load than processing speech in the auditory modality alone.</description>
    </item>
    <item>
      <title>&#34;Paying&#34; Attention to Audiovisual Speech: Do Incongruent Stimuli Incur Greater Costs?</title>
      <link>https://www.violetabrown.com/publications/brown_strand_2019_app/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/brown_strand_2019_app/</guid>
      <description>The McGurk effect is a multisensory phenomenon in which discrepant auditory and visual speech signals typically result in an illusory percept. McGurk stimuli are often used in studies assessing the attentional requirements of audiovisual integration, but no study has directly compared the costs associated with integrating congruent versus incongruent audiovisual speech. Some evidence suggests that the McGurk effect may not be representative of naturalistic audiovisual speech processing – susceptibility to the McGurk effect is not associated with the ability to derive benefit from the addition of the visual signal, and distinct cortical regions are recruited when processing congruent versus incongruent speech.</description>
    </item>
    <item>
      <title>Noise Increases Listening Effort in Normal-Hearing Young Adults, Regardless of Working Memory Capacity</title>
      <link>https://www.violetabrown.com/publications/brown_strand_2018/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.violetabrown.com/publications/brown_strand_2018/</guid>
      <description>As listening conditions worsen (e.g. background noise increases), additional cognitive effort is required to process speech. The existing literature is mixed on whether and how cognitive traits like working memory capacity moderate the amount of effort that listeners must expend to successfully understand speech. Here, we validate a dual-task measure of listening effort (Experiment 1) and demonstrate that for normal-hearing young adults, effort increases as steady-state masking noise increases, but working memory capacity is unrelated to the amount of effort expended (Experiment 2).</description>
    </item>
  </channel>
</rss>
